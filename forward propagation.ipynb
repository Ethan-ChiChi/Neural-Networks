{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a single image of FashionMNIST with forward propagation\n",
    "## input : 1 × 28 × 28\n",
    "## output: 1 × 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST'\n",
    "    ,train = True\n",
    "    , download = True\n",
    "    , transform =transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        \n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        \n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        \n",
    "        t = F.relu(self.fc1(t))\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        \n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t,dim = 1)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x22f39a75a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_set)) # the first image in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = sample\n",
    "image.shape #  a sigal image with label 9 (Ankle boot) will transmit through nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.unsqueeze(0).shape # this give us a batch with size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = network(image.unsqueeze(0)) # image shape needs to be (batch_size × in_channels × H × W )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0022, -0.0183,  0.0559,  0.0380,  0.0372,  0.0746,  0.0706, -0.1070, -0.0628, -0.0647]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(dim = 1) # the prediction in this case is incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0994, 0.0978, 0.1053, 0.1035, 0.1034, 0.1073, 0.1069, 0.0895, 0.0935, 0.0934]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(pred,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network weights are randomly generated. Each time we create a new instance of our network, the weights within the network will be different. This means that the predictions we get will be different if we create different networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(pred, dim=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0223,  0.1937,  0.0145, -0.1463, -0.1362],\n",
       "          [-0.0176, -0.1004, -0.1849,  0.0675, -0.1715],\n",
       "          [ 0.1360,  0.0861,  0.1588, -0.1981, -0.1969],\n",
       "          [-0.1239,  0.0620,  0.0521,  0.0004,  0.0939],\n",
       "          [ 0.0705, -0.0191, -0.0849, -0.0874,  0.0426]]],\n",
       "\n",
       "\n",
       "        [[[-0.1045, -0.1695, -0.1428,  0.0501, -0.1895],\n",
       "          [-0.0589,  0.0844,  0.1490,  0.1911,  0.1579],\n",
       "          [-0.0212,  0.0917, -0.0421, -0.0755, -0.1491],\n",
       "          [-0.0199,  0.1599, -0.1593, -0.1041, -0.0893],\n",
       "          [-0.1800,  0.1123,  0.0095,  0.1188, -0.0050]]],\n",
       "\n",
       "\n",
       "        [[[-0.0440,  0.1306, -0.1850,  0.0351,  0.1271],\n",
       "          [-0.1005, -0.1520,  0.0990, -0.0930,  0.0393],\n",
       "          [ 0.1182, -0.0668, -0.0547, -0.0179,  0.0718],\n",
       "          [-0.0218,  0.1389, -0.0575, -0.0886,  0.1490],\n",
       "          [ 0.1632,  0.1838,  0.1496, -0.0337, -0.1269]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0151, -0.1776, -0.0718, -0.1233, -0.0684],\n",
       "          [ 0.1111,  0.0321, -0.0381,  0.1587,  0.0638],\n",
       "          [ 0.0258, -0.0444, -0.0930, -0.0899, -0.1649],\n",
       "          [-0.0024,  0.1417,  0.0109, -0.0523,  0.1801],\n",
       "          [ 0.0110,  0.0720,  0.1746,  0.1562,  0.0394]]],\n",
       "\n",
       "\n",
       "        [[[-0.1765,  0.1394, -0.0241,  0.0968,  0.0223],\n",
       "          [ 0.1617, -0.1505,  0.1226, -0.0055,  0.0928],\n",
       "          [-0.0234,  0.0704,  0.1976, -0.1099, -0.0636],\n",
       "          [-0.1731,  0.0182,  0.0652, -0.1505,  0.0285],\n",
       "          [-0.0825,  0.0708, -0.0531,  0.1703,  0.1378]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0295,  0.1620,  0.1821, -0.0075, -0.0549],\n",
       "          [-0.0746,  0.1570,  0.0322,  0.1358,  0.0547],\n",
       "          [ 0.1252,  0.0210,  0.0045, -0.0796, -0.0604],\n",
       "          [ 0.0298,  0.1891,  0.0505,  0.0972, -0.0219],\n",
       "          [ 0.1168,  0.1740,  0.0875,  0.0678, -0.0205]]]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0018,  0.0078,  0.0129,  ...,  0.0271,  0.0717,  0.0343],\n",
       "        [ 0.0601, -0.0669,  0.0465,  ..., -0.0249,  0.0662, -0.0495],\n",
       "        [-0.0681,  0.0158, -0.0437,  ..., -0.0292, -0.0489, -0.0326],\n",
       "        ...,\n",
       "        [ 0.0178,  0.0468, -0.0143,  ...,  0.0460,  0.0661, -0.0047],\n",
       "        [-0.0482,  0.0383, -0.0506,  ...,  0.0604, -0.0186, -0.0660],\n",
       "        [-0.0244, -0.0491,  0.0379,  ..., -0.0438,  0.0332,  0.0628]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 192])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc1.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([12, 6, 5, 5])\n",
      "torch.Size([12])\n",
      "torch.Size([120, 192])\n",
      "torch.Size([120])\n",
      "torch.Size([60, 120])\n",
      "torch.Size([60])\n",
      "torch.Size([10, 60])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for para in network.parameters():\n",
    "    print(para.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, para in network.named_parameters():\n",
    "    print(name, '\\t\\t', para.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = torch.tensor([1,2,3,4], dtype =torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = torch.tensor([\n",
    "    [1,2,3,4],\n",
    "    [2,3,4,5],\n",
    "    [3,4,5,6]\n",
    "], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30., 40., 50.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix.matmul(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(in_features=4, out_features=3, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.weight = nn.Parameter(weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30., 40., 50.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc(in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
